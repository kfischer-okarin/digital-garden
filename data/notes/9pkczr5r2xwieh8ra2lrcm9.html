<h1 id="autoencoder">Autoencoder<a aria-hidden="true" class="anchor-heading icon-link" href="#autoencoder"></a></h1>
<ul>
<li>A neural network that tries to reproduce the training data exactly (i.e. learn the identity function)</li>
<li>It has one hidden layer (called the Bottleneck) with less neurons than the input layer
<ul>
<li>This will be the representation of the data's characteristics - by using fewer neurons than the original data
dimension the network is forced to learn the relevant characteristics</li>
</ul>
</li>
<li>The data itself are the label - thus it is not a classic supervised learning approach but a self-supervised learning
approach</li>
</ul>
<h2 id="applications">Applications<a aria-hidden="true" class="anchor-heading icon-link" href="#applications"></a></h2>
<ul>
<li>Anomaly Detection
<ul>
<li>Train with lots of good, normal data</li>
<li>Feeding the network an irregular broken data point should result in an irregularly high error</li>
</ul>
</li>
<li>Noise Reduction
<ul>
<li>Train a certain type of data by adding random noise to it and using the original clean data as label</li>
</ul>
</li>
<li>Other uses:
<ul>
<li>information retrieval, imputation, feature extraction, and dimensionality reduction problems
<ul>
<li>TODO: Expand on those</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="resources">Resources<a aria-hidden="true" class="anchor-heading icon-link" href="#resources"></a></h2>
<ul>
<li><a href="https://articles.bnomial.com/autoencoders">Autoencoders on bnomial</a></li>
</ul>